{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method taken from SentEval Examples\n",
    "def get_dictionary(sentences, threshold=0):\n",
    "    words = {}\n",
    "    for s in sentences:\n",
    "        for word in s:\n",
    "            words[word] = words.get(word, 0) + 1\n",
    "\n",
    "    if threshold > 0:\n",
    "        newwords = {}\n",
    "        for word in words:\n",
    "            if words[word] >= threshold:\n",
    "                newwords[word] = words[word]\n",
    "        words = newwords\n",
    "    words['<s>'] = 1e9 + 4\n",
    "    words['</s>'] = 1e9 + 3\n",
    "    words['<p>'] = 1e9 + 2\n",
    "\n",
    "    sorted_words = sorted(words.items(), key=lambda x: -x[1])  # inverse sort\n",
    "    id2word = []\n",
    "    word2id = {}\n",
    "    for i, (w, _) in enumerate(sorted_words):\n",
    "        id2word.append(w)\n",
    "        word2id[w] = i\n",
    "\n",
    "    return id2word, word2id\n",
    "\n",
    "\n",
    "# Skip gram word2vec\n",
    "def get_wordvec(model, word2id):\n",
    "    '''\n",
    "    model: gensim trained skipgram model\n",
    "    word2id: word2index\n",
    "    '''\n",
    "    word_vec = {}\n",
    "    \n",
    "    for word in word2id:\n",
    "        if word in model.wv.vocab:\n",
    "            word_vec[word] = model.wv[word]\n",
    "\n",
    "    return word_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-31 13:44:32,383 : loading Word2Vec object from model/200_10_20_skip.bin\n",
      "2018-05-31 13:44:32,384 : {'kw': {}, 'mode': 'rb', 'uri': 'model/200_10_20_skip.bin'}\n",
      "2018-05-31 13:44:32,385 : encoding_wrapper: {'mode': 'rb', 'errors': 'strict', 'fileobj': <_io.BufferedReader name='model/200_10_20_skip.bin'>, 'encoding': None}\n",
      "2018-05-31 13:44:32,839 : loading wv recursively from model/200_10_20_skip.bin.wv.* with mmap=None\n",
      "2018-05-31 13:44:32,840 : setting ignored attribute vectors_norm to None\n",
      "2018-05-31 13:44:32,841 : loading vocabulary recursively from model/200_10_20_skip.bin.vocabulary.* with mmap=None\n",
      "2018-05-31 13:44:32,842 : loading trainables recursively from model/200_10_20_skip.bin.trainables.* with mmap=None\n",
      "2018-05-31 13:44:32,843 : setting ignored attribute cum_table to None\n",
      "2018-05-31 13:44:32,843 : loaded model/200_10_20_skip.bin\n",
      "2018-05-31 13:44:32,960 : ***** Transfer task : MR *****\n",
      "\n",
      "\n",
      "2018-05-31 13:44:33,160 : Generating sentence embeddings\n",
      "2018-05-31 13:44:33,637 : Generated sentence embeddings\n",
      "2018-05-31 13:44:33,639 : Training sklearn-LogReg with (inner) 10-fold cross-validation\n",
      "2018-05-31 13:44:46,599 : Best param found at split 1: l2reg = 2                 with score 69.76\n",
      "2018-05-31 13:44:59,746 : Best param found at split 2: l2reg = 0.25                 with score 70.11\n",
      "2018-05-31 13:45:12,348 : Best param found at split 3: l2reg = 0.5                 with score 69.92\n",
      "2018-05-31 13:45:24,881 : Best param found at split 4: l2reg = 0.25                 with score 69.86\n",
      "2018-05-31 13:45:37,449 : Best param found at split 5: l2reg = 0.25                 with score 70.01\n",
      "2018-05-31 13:45:49,969 : Best param found at split 6: l2reg = 0.25                 with score 69.91\n",
      "2018-05-31 13:46:02,597 : Best param found at split 7: l2reg = 8                 with score 69.87\n",
      "2018-05-31 13:46:15,114 : Best param found at split 8: l2reg = 0.5                 with score 69.48\n",
      "2018-05-31 13:46:27,788 : Best param found at split 9: l2reg = 0.25                 with score 70.04\n",
      "2018-05-31 13:46:40,357 : Best param found at split 10: l2reg = 0.5                 with score 70.13\n",
      "2018-05-31 13:46:40,574 : Dev acc : 69.91 Test acc : 69.95\n",
      "\n",
      "2018-05-31 13:46:40,576 : ***** Transfer task : CR *****\n",
      "\n",
      "\n",
      "2018-05-31 13:46:40,627 : Generating sentence embeddings\n",
      "2018-05-31 13:46:40,745 : Generated sentence embeddings\n",
      "2018-05-31 13:46:40,746 : Training sklearn-LogReg with (inner) 10-fold cross-validation\n",
      "2018-05-31 13:46:44,806 : Best param found at split 1: l2reg = 0.25                 with score 75.12\n",
      "2018-05-31 13:46:48,899 : Best param found at split 2: l2reg = 0.25                 with score 74.68\n",
      "2018-05-31 13:46:53,118 : Best param found at split 3: l2reg = 0.25                 with score 75.07\n",
      "2018-05-31 13:46:57,242 : Best param found at split 4: l2reg = 0.5                 with score 74.98\n",
      "2018-05-31 13:47:01,315 : Best param found at split 5: l2reg = 0.5                 with score 74.98\n",
      "2018-05-31 13:47:05,323 : Best param found at split 6: l2reg = 0.25                 with score 75.18\n",
      "2018-05-31 13:47:09,354 : Best param found at split 7: l2reg = 0.5                 with score 74.63\n",
      "2018-05-31 13:47:13,567 : Best param found at split 8: l2reg = 2                 with score 75.34\n",
      "2018-05-31 13:47:17,696 : Best param found at split 9: l2reg = 0.5                 with score 74.69\n",
      "2018-05-31 13:47:21,845 : Best param found at split 10: l2reg = 0.5                 with score 75.0\n",
      "2018-05-31 13:47:21,924 : Dev acc : 74.97 Test acc : 74.94\n",
      "\n",
      "2018-05-31 13:47:21,925 : ***** Transfer task : MPQA *****\n",
      "\n",
      "\n",
      "2018-05-31 13:47:22,035 : Generating sentence embeddings\n",
      "2018-05-31 13:47:22,219 : Generated sentence embeddings\n",
      "2018-05-31 13:47:22,220 : Training sklearn-LogReg with (inner) 10-fold cross-validation\n",
      "2018-05-31 13:47:32,957 : Best param found at split 1: l2reg = 0.25                 with score 84.93\n",
      "2018-05-31 13:47:43,973 : Best param found at split 2: l2reg = 0.25                 with score 85.08\n",
      "2018-05-31 13:47:55,000 : Best param found at split 3: l2reg = 0.5                 with score 84.87\n",
      "2018-05-31 13:48:05,975 : Best param found at split 4: l2reg = 0.5                 with score 85.33\n",
      "2018-05-31 13:48:17,070 : Best param found at split 5: l2reg = 0.25                 with score 85.1\n",
      "2018-05-31 13:48:28,065 : Best param found at split 6: l2reg = 0.25                 with score 84.9\n",
      "2018-05-31 13:48:39,077 : Best param found at split 7: l2reg = 0.25                 with score 85.21\n",
      "2018-05-31 13:48:50,030 : Best param found at split 8: l2reg = 0.25                 with score 85.09\n",
      "2018-05-31 13:49:01,087 : Best param found at split 9: l2reg = 0.25                 with score 85.19\n",
      "2018-05-31 13:49:12,181 : Best param found at split 10: l2reg = 0.5                 with score 84.8\n",
      "2018-05-31 13:49:12,388 : Dev acc : 85.05 Test acc : 84.99\n",
      "\n",
      "2018-05-31 13:49:12,389 : ***** Transfer task : SUBJ *****\n",
      "\n",
      "\n",
      "2018-05-31 13:49:12,527 : Generating sentence embeddings\n",
      "2018-05-31 13:49:12,849 : Generated sentence embeddings\n",
      "2018-05-31 13:49:12,850 : Training sklearn-LogReg with (inner) 10-fold cross-validation\n",
      "2018-05-31 13:49:25,265 : Best param found at split 1: l2reg = 0.25                 with score 83.79\n",
      "2018-05-31 13:49:37,392 : Best param found at split 2: l2reg = 0.25                 with score 83.83\n",
      "2018-05-31 13:49:49,753 : Best param found at split 3: l2reg = 1                 with score 84.06\n",
      "2018-05-31 13:50:02,395 : Best param found at split 4: l2reg = 0.5                 with score 83.96\n",
      "2018-05-31 13:50:14,535 : Best param found at split 5: l2reg = 0.5                 with score 83.77\n",
      "2018-05-31 13:50:27,559 : Best param found at split 6: l2reg = 1                 with score 83.97\n",
      "2018-05-31 13:50:39,644 : Best param found at split 7: l2reg = 1                 with score 83.97\n",
      "2018-05-31 13:50:51,776 : Best param found at split 8: l2reg = 0.25                 with score 84.01\n",
      "2018-05-31 13:51:03,556 : Best param found at split 9: l2reg = 0.25                 with score 83.81\n",
      "2018-05-31 13:51:15,604 : Best param found at split 10: l2reg = 0.25                 with score 83.8\n",
      "2018-05-31 13:51:15,764 : Dev acc : 83.9 Test acc : 84.13\n",
      "\n",
      "2018-05-31 13:51:15,765 : ***** Transfer task : SST Binary classification *****\n",
      "\n",
      "\n",
      "2018-05-31 13:51:16,150 : Computing embedding for dev\n",
      "2018-05-31 13:51:16,184 : Computed dev embeddings\n",
      "2018-05-31 13:51:16,185 : Computing embedding for train\n",
      "2018-05-31 13:51:17,771 : Computed train embeddings\n",
      "2018-05-31 13:51:17,772 : Computing embedding for test\n",
      "2018-05-31 13:51:17,939 : Computed test embeddings\n",
      "2018-05-31 13:51:17,939 : Training sklearn-LogReg with standard validation..\n",
      "2018-05-31 13:51:26,389 : [('reg:0.25', 71.22), ('reg:0.5', 71.1), ('reg:1', 71.1), ('reg:2', 71.1), ('reg:4', 71.1), ('reg:8', 71.1)]\n",
      "2018-05-31 13:51:26,390 : Validation : best param found is reg = 0.25 with score             71.22\n",
      "2018-05-31 13:51:26,390 : Evaluating...\n",
      "2018-05-31 13:51:27,779 : \n",
      "Dev acc : 71.22 Test acc : 72.71 for             SST Binary classification\n",
      "\n",
      "2018-05-31 13:51:27,783 : ***** Transfer task : TREC *****\n",
      "\n",
      "\n",
      "2018-05-31 13:51:28,001 : Computed train embeddings\n",
      "2018-05-31 13:51:28,012 : Computed test embeddings\n",
      "2018-05-31 13:51:28,014 : Training sklearn-LogReg with 10-fold cross-validation\n",
      "2018-05-31 13:52:16,473 : [('reg:0.5', 62.18), ('reg:1', 62.15), ('reg:2', 62.04), ('reg:4', 61.91), ('reg:8', 61.82), ('reg:16', 61.78), ('reg:32', 61.71)]\n",
      "2018-05-31 13:52:16,474 : Cross-validation : best param found is reg = 0.5             with score 62.18\n",
      "2018-05-31 13:52:16,474 : Evaluating...\n",
      "2018-05-31 13:52:17,109 : \n",
      "Dev acc : 62.18 Test acc : 62.8             for TREC\n",
      "\n",
      "2018-05-31 13:52:17,110 : ***** Transfer task : MRPC *****\n",
      "\n",
      "\n",
      "2018-05-31 13:52:17,246 : Computing embedding for train\n",
      "2018-05-31 13:52:17,491 : Computed train embeddings\n",
      "2018-05-31 13:52:17,492 : Computing embedding for test\n",
      "2018-05-31 13:52:17,610 : Computed test embeddings\n",
      "2018-05-31 13:52:17,617 : Training sklearn-LogReg with 10-fold cross-validation\n",
      "2018-05-31 13:52:31,050 : [('reg:0.5', 70.27), ('reg:1', 70.14), ('reg:2', 69.73), ('reg:4', 69.65), ('reg:8', 69.19), ('reg:16', 69.09), ('reg:32', 69.19)]\n",
      "2018-05-31 13:52:31,051 : Cross-validation : best param found is reg = 0.5             with score 70.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-31 13:52:31,051 : Evaluating...\n",
      "2018-05-31 13:52:31,193 : Dev acc : 70.27 Test acc 71.01; Test F1 80.78 for MRPC.\n",
      "\n",
      "2018-05-31 13:52:31,194 : ***** Transfer task : SICK-Entailment*****\n",
      "\n",
      "\n",
      "2018-05-31 13:52:31,288 : Computing embedding for dev\n",
      "2018-05-31 13:52:31,324 : Computed dev embeddings\n",
      "2018-05-31 13:52:31,324 : Computing embedding for train\n",
      "2018-05-31 13:52:31,524 : Computed train embeddings\n",
      "2018-05-31 13:52:31,525 : Computing embedding for test\n",
      "2018-05-31 13:52:31,733 : Computed test embeddings\n",
      "2018-05-31 13:52:31,746 : Training sklearn-LogReg with standard validation..\n",
      "2018-05-31 13:52:35,545 : [('reg:0.25', 69.0), ('reg:0.5', 68.4), ('reg:1', 68.6), ('reg:2', 67.0), ('reg:4', 65.4), ('reg:8', 65.2)]\n",
      "2018-05-31 13:52:35,545 : Validation : best param found is reg = 0.25 with score             69.0\n",
      "2018-05-31 13:52:35,546 : Evaluating...\n",
      "2018-05-31 13:52:35,970 : \n",
      "Dev acc : 69.0 Test acc : 70.06 for                        SICK entailment\n",
      "\n",
      "2018-05-31 13:52:35,971 : ***** Transfer task : STS14 *****\n",
      "\n",
      "\n",
      "SentEval/senteval/utils.py:39: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
      "2018-05-31 13:52:36,091 : deft-forum : pearson = 0.4077, spearman = 0.3962\n",
      "2018-05-31 13:52:36,127 : deft-news : pearson = 0.7062, spearman = 0.6663\n",
      "2018-05-31 13:52:36,204 : headlines : pearson = 0.5907, spearman = 0.5548\n",
      "2018-05-31 13:52:36,285 : images : pearson = 0.7557, spearman = 0.7258\n",
      "2018-05-31 13:52:36,359 : OnWN : pearson = 0.7705, spearman = 0.7868\n",
      "2018-05-31 13:52:36,439 : tweet-news : pearson = 0.6870, spearman = 0.6289\n",
      "2018-05-31 13:52:36,440 : ALL (weighted average) : Pearson = 0.6662,             Spearman = 0.6401\n",
      "2018-05-31 13:52:36,440 : ALL (average) : Pearson = 0.6529,             Spearman = 0.6265\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MRPC': {'f1': 80.78, 'ndev': 4076, 'devacc': 70.27, 'ntest': 1725, 'acc': 71.01}, 'SUBJ': {'ndev': 10000, 'devacc': 83.9, 'ntest': 10000, 'acc': 84.13}, 'SST2': {'ndev': 872, 'devacc': 71.22, 'ntest': 1821, 'acc': 72.71}, 'MPQA': {'ndev': 10606, 'devacc': 85.05, 'ntest': 10606, 'acc': 84.99}, 'TREC': {'ndev': 5452, 'devacc': 62.18, 'ntest': 500, 'acc': 62.8}, 'SICKEntailment': {'ndev': 500, 'devacc': 69.0, 'ntest': 4927, 'acc': 70.06}, 'STS14': {'all': {'spearman': {'mean': 0.6264608768182562, 'wmean': 0.6400951189476622}, 'pearson': {'mean': 0.6529429836676489, 'wmean': 0.6661760356081586}}, 'deft-news': {'nsamples': 300, 'spearman': SpearmanrResult(correlation=0.666322124925226, pvalue=7.192141899761077e-40), 'pearson': (0.7061927534573326, 1.3415285600255232e-46)}, 'OnWN': {'nsamples': 750, 'spearman': SpearmanrResult(correlation=0.7867638353783685, pvalue=6.850496592676228e-159), 'pearson': (0.7705091308881843, 1.961780466557028e-148)}, 'headlines': {'nsamples': 750, 'spearman': SpearmanrResult(correlation=0.5547609712986548, pvalue=9.45169660515674e-62), 'pearson': (0.5906610332369502, 1.0035642337124787e-71)}, 'images': {'nsamples': 750, 'spearman': SpearmanrResult(correlation=0.72578394579509, pvalue=1.2110916369559818e-123), 'pearson': (0.7556812638799155, 1.2722925097757388e-139)}, 'deft-forum': {'nsamples': 450, 'spearman': SpearmanrResult(correlation=0.39624097804022707, pvalue=2.278463179619569e-18), 'pearson': (0.4076551797267521, 1.9095344535046383e-19)}, 'tweet-news': {'nsamples': 750, 'spearman': SpearmanrResult(correlation=0.6288934054719708, pvalue=8.049084238560391e-84), 'pearson': (0.6869585408167591, 8.306392730252052e-106)}}, 'CR': {'ndev': 3775, 'devacc': 74.97, 'ntest': 3775, 'acc': 74.94}, 'MR': {'ndev': 10662, 'devacc': 69.91, 'ntest': 10662, 'acc': 69.95}}\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) 2017-present, Facebook, Inc.\n",
    "# All rights reserved.\n",
    "#\n",
    "# This source code is licensed under the license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "#\n",
    "\n",
    "from __future__ import absolute_import, division, unicode_literals\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import logging\n",
    "import sklearn\n",
    "# import SentEval.examples.data as data\n",
    "\n",
    "# Set PATHs\n",
    "# path to senteval\n",
    "PATH_TO_SENTEVAL = 'SentEval/'\n",
    "# path to the NLP datasets \n",
    "PATH_TO_DATA = 'SentEval/data'\n",
    "# path to SkipGram model\n",
    "PATH_TO_VEC = 'model/200_10_20_skip.bin'\n",
    "model = models.Word2Vec.load(PATH_TO_VEC)\n",
    "\n",
    "# import SentEval\n",
    "sys.path.insert(0, PATH_TO_SENTEVAL)\n",
    "import senteval\n",
    "\n",
    "\n",
    "def prepare(params, samples):\n",
    "    \"\"\"\n",
    "    For Skip gram,\n",
    "    \"\"\"\n",
    "    _, params.word2id = get_dictionary(samples)\n",
    "    # load glove/word2vec format \n",
    "    params.word_vec = get_wordvec(model, params.word2id)\n",
    "    # dimensionality of Skip embeddings\n",
    "    params.wvec_dim = 200\n",
    "    return\n",
    "\n",
    "def batcher(params, batch):\n",
    "    \"\"\"\n",
    "    For Skip gram\n",
    "    \n",
    "    \"\"\"\n",
    "    # if a sentence is empty dot is set to be the only token\n",
    "    batch = [sent if sent != [] else [''] for sent in batch]\n",
    "    embeddings = []\n",
    "\n",
    "    for sent in batch:\n",
    "        sentvec = []\n",
    "        # the format of a sentence is a lists of words (tokenized and lowercased)\n",
    "        for word in sent:\n",
    "            if word in params.word_vec:\n",
    "                # [number of words, embedding dimensionality]\n",
    "                sentvec.append(params.word_vec[word])\n",
    "        if not sentvec:\n",
    "            vec = np.zeros(params.wvec_dim)\n",
    "            # [number of words, embedding dimensionality]\n",
    "            sentvec.append(vec)\n",
    "        # average of word embeddings for sentence representation\n",
    "        # [embedding dimansionality]\n",
    "        sentvec = np.mean(sentvec, 0)\n",
    "        embeddings.append(sentvec)\n",
    "    # [batch size, embedding dimensionality]\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "# Set params for SentEval\n",
    "# we use logistic regression (usepytorch: Fasle) and kfold 10\n",
    "# In this dictionary you can add extra information that you model needs for initialization\n",
    "# for example the path to a dictionary of indices, of hyper parameters\n",
    "# this dictionary is passed to the batched and the prepare fucntions\n",
    "params_senteval = {'task_path': PATH_TO_DATA, 'usepytorch': False, 'kfold': 10}\n",
    "# this is the config for the NN classifier but we are going to use scikit-learn logistic regression with 10 kfold\n",
    "# usepytorch = False \n",
    "#params_senteval['classifier'] = {'nhid': 0, 'optim': 'rmsprop', 'batch_size': 128,\n",
    "#                                 'tenacity': 3, 'epoch_size': 2}\n",
    "\n",
    "# Set up logger\n",
    "logging.basicConfig(format='%(asctime)s : %(message)s', level=logging.DEBUG)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    se = senteval.engine.SE(params_senteval, batcher, prepare)\n",
    "    \n",
    "    # here you define the NLP taks that your embedding model is going to be evaluated\n",
    "    # in (https://arxiv.org/abs/1802.05883) we use the following :\n",
    "    # SICKRelatedness (Sick-R) needs torch cuda to work (even when using logistic regression), \n",
    "    # but STS14 (semantic textual similarity) is a similar type of semantic task\n",
    "    transfer_tasks = ['MR', 'CR', 'MPQA', 'SUBJ', 'SST2', 'TREC',\n",
    "                      'MRPC', 'SICKEntailment', 'STS14']\n",
    "    # senteval prints the results and returns a dictionary with the scores\n",
    "    results = se.eval(transfer_tasks)\n",
    "    print(results)\n",
    "    with open(os.path.join(\"model\",\"200_10_20_skip.pkl\"),'wb') as f:\n",
    "        pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
